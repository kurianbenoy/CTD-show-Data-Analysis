{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir('../input/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"episode = pd.read_csv('../input/chai-time-data-science/Episodes.csv')\ndesc = pd.read_csv('../input/chai-time-data-science/Description.csv')","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"episode[episode['episode_id']==\"E69\"][\"release_date\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- If you have listened to that episode, Sanyanam had said he has turned into age of 23. So his DOB is: 27/05/1997","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_transcript(fn, save=False, save_path=''):\n    \"Takes transcript and converts it to `DataFrame`\"\n    pat = r'([A-Za-z]|\\s+)\\s([0-9]{0,2}:{0,1}[0-9]{1,2}:[0-9][0-9])'\n    f = open(fn, \"r\")\n    t = True\n    df = pd.DataFrame(columns = ['Time', 'Speaker', 'Text'])\n    i = 0\n    first = True\n    while t:\n        line = f.readline()\n        if line == '': t = False\n        i += 1\n        line = re.split(pat, line[:-1])\n        if len(line) == 4:\n            is_new = 1\n            speak = line[0]\n            time = line[2]\n        while is_new == 1:\n            if first:\n                line = f.readline()\n                for i in range(6):\n                    l_c = f.readline()\n                    if speak not in l_c and time not in l_c:\n                        line += l_c\n                i += 1\n                first = False\n            else:\n                line = f.readline()\n                i += 1\n            if len(line) > 2 and line != '\\n':\n                line = line[:-1]\n                df.loc[i] = [time, speak, line]\n                df.reset_index()\n            else:\n                is_new = 0\n    df.reset_index(drop=True, inplace=True)\n    df['Text'] = df['Text'].replace('\\n', '')\n    if save:\n        df.to_csv(save_path+fn.name[:-3] + 'csv', index=False, sep='|')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_transcript(fn, save=False, save_path=''):\n    \"Takes transcript and converts it to `DataFrame`\"\n    pat = r'([A-Za-z]|\\s+)\\s([0-9]{0,2}:{0,1}[0-9]{1,2}:[0-9][0-9])'\n    f = open(fn, \"r\")\n    t = True\n    df = pd.DataFrame(columns = ['Time', 'Speaker', 'Text'])\n    i = 0\n    first = True\n    while t:\n        line = f.readline()\n        if line == '': t = False\n        i += 1\n        line = re.split(pat, line[:-1])\n        if len(line) == 4:\n            is_new = 1\n            speak = line[0]\n            time = line[2]\n        while is_new == 1:\n            if first:\n                line = f.readline()\n                for i in range(6):\n                    l_c = f.readline()\n                    if speak not in l_c and time not in l_c:\n                        line += l_c\n                i += 1\n                first = False\n            else:\n                line = f.readline()\n                i += 1\n            if len(line) > 2 and line != '\\n':\n                line = line[:-1]\n                df.loc[i] = [time, speak, line]\n                df.reset_index()\n            else:\n                is_new = 0\n    df.reset_index(drop=True, inplace=True)\n    df['Text'] = df['Text'].replace('\\n', '')\n    if save:\n        df.to_csv(save_path+fn.name[:-3] + 'csv', index=False, sep='|')\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_filenames(path):\n    dir_name = []\n    for f_name in os.listdir(path):\n        dir_name.append(f_name)\n    return dir_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"li = get_filenames('../input/chai-time-data-science/Raw Subtitles/')","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"df = extract_transcript('../input/chai-time-data-science/Raw Subtitles/E1.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"episode_1 = pd.read_csv('../input/chai-time-data-science/Cleaned Subtitles/E1.csv')\nepisode_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=episode_1.Speaker.value_counts()\nsns.barplot(x.index, x)\nplt.gca().set_ylabel('Times spoken')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"episode_1[episode_1[\"Speaker\"]==\"Sanyam Bhutani\"][\"Text\"].str.len()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nsany_len = episode_1[episode_1[\"Speaker\"]==\"Sanyam Bhutani\"][\"Text\"].str.len()\nax1.hist(sany_len,color='red')\nax1.set_title('Sanyanam Bhutani')\nabhi_len = episode_1[episode_1[\"Speaker\"]==\"Abhishek Thakur\"][\"Text\"].str.len()\nax2.hist(abhi_len,color='green')\nax2.set_title('Abhishek Thakur')\nfig.suptitle('Characters in Conversations')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## No of words in tweets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nsany_len = episode_1[episode_1[\"Speaker\"]==\"Sanyam Bhutani\"][\"Text\"].str.split().map(lambda x: len(x))\nax1.hist(sany_len,color='red')\nax1.set_title('Sanyanam Bhutani')\nabhi_len = episode_1[episode_1[\"Speaker\"]==\"Abhishek Thakur\"][\"Text\"].str.split().map(lambda x: len(x))\nax2.hist(abhi_len,color='green')\nax2.set_title('Abhishek Thakur')\nfig.suptitle('Words in each conversation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"episode_2 = pd.read_csv('../input/chai-time-data-science/Cleaned Subtitles/E2.csv')\nepisode_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = episode_2.Speaker.value_counts()\nsns.barplot(x.index,x)\nplt.gca().set_ylabel('Times spoken')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"episode_1['Text'].loc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"episode_n = pd.read_csv('input/Cleaned Subtitles/E75.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"intro_n = episode_n['Text'].loc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(intro_n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"intro_1 = episode_1['Text'].loc[0]\nlen(intro_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What are the future plans for Chai time data science?\n\n- what are the top enhancements or changes you're working on for CTDS? Anything to look forward to, in the near future?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ama_episode = pd.read_csv('../input/chai-time-data-science/Cleaned Subtitles/E69.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ama_episode['Text'][1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And yes, there are a lot of exciting things that I am I\\'ve been working on. So three things. I\\'m launching a new podcast. Yes, a new podcast called \"Chai Time Data Science News\" CTDS.news. You can find another write up that will live with this blog post. You can read all about it. But the idea is to give you a short news podcast, ideally in three to five minutes, always less than 10 minutes for you to be able to be on top of data science news, basically. Now if you know me, I am completely community driven. So if you have any thoughts around around that, please let me know the first episode is supposed to go live somewhere in the first week of June, so in a few days from now, but we\\'ll see how that goes. Secondly, you as you might know, I have been subtitling, every single one of the interview that goes out is all of the two interviews that go out and have been going on since January. And now I will be starting a blog version release of these also in the first week of June or probably before that. So you can read you can expect blog releases and also short, interesting parts of the conversation short clips. I was going to call it cutting chai shorts from \"Chai Time Data Science.\\' So really excited about that. I also have a new set a new camera a new mic my new look. But we\\'ll see how that goes. The \"Chai Time Data Science\" story, how did it all begin? So, I have been interviewing my heroes on machine learning in a blog format. And I started that in my third year of studies third year of university. I did almost 25 interviews but after a point did it start I started feeling it was getting repetitive. My questions were getting repetitive and I I didn\\'t want to just go out there and waste these amazing people that were giving me their time, their time. Also, to me it was feeling like I was asking these heroes of mine to write the blog posts for me It means that that\\'s how it would fit into my pipe and I\\'ll send them in questions they would write the answers back. Another thing that I really wanted to do was I, luckily, was able to interview many Kaggle Grand Masters many Kaggle Masters. And I wanted to apply their advice myself. So this might not happen in parallel, but I focus more on Kaggle, I really focus on Kaggle at least so six, seven months that I was active on the platform. And right around the last few months of my activity, I actually made it to the finals of the Google air residency programme. So I was also freelancing at that time freelancing because you\\'re not allowed to have a job job in college. And I had opted out of college placement. So in India, your college helps you get a job. I had opted out of that very boldly because I didn\\'t see any machine learning related roles. I was gonna my I thought might as well just get if I really want to do this if, if I\\'m not confident enough, why dare I say that I\\'d love to be a part of this field. So I did that. And if you have worked in consulting or freelancing, you know, when it rains, it pours. And when it doesn\\'t, it\\'s drier than a desert. So the Google a residency'","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}